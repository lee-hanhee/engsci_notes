\subsection{Summary}
\begin{intuition}
    \begin{itemize}
        \item Limitations of the perceptron
        \item Decomposing of a complex problem
        \item Differentiable activation functions (sgn to logistic, tanh)
        \item Neural networks
        \item Applications to Genomics
        \item Forward propogation
        \item Back propogation
    \end{itemize}
\end{intuition}

\subsection{Motivation for neural networks}

\subsubsection{Limitation of perceptron}
\begin{intuition}
    It cannot deal with linearly inseparable data. 
    \customFigure[0.5]{00_Images/LI.png}{Linearly inseparable.}
\end{intuition}

\subsubsection{Decomposing a complex problem}
\begin{intuition}
    Take a divide and conquer approach.
    \begin{itemize}
        \item Divide the problem into $h_1$ and $h_2$. 
        \item Then you can use AND, NOT, and OR to decompose the problem into a binary encoding that repesents the 4 quadrants based on the value of $h_1$ and $h_2$. 
    \end{itemize}
    \customFigure[0.75]{00_Images/CP.png}{Decomposing the complex problem to be constructed from $f$.}
\end{intuition}

\subsubsection{Representing as a multilayer perceptron}
\begin{definition}
    \customFigure[0.75]{00_Images/MLP.png}{Multilayer Perceptron}
    \begin{itemize}
        \item \textbf{DAG:} Directed acyclic graph with weights on the edges. 
        \item \textbf{Note:} The MLP is built up with the components of AND and OR with $-1$ representing the not. 
    \end{itemize}
    \begin{itemize}
        \item \textbf{OR Gate Implementation:}
        \begin{itemize}
            \item Inputs: \( x_1 \), \( x_2 \)
            \item Weights: \( w_1 = 1 \), \( w_2 = 1 \)
            \item Bias: \( -0.5 \)
            \item Output: 
            \[
            \text{Output} = 
            \begin{cases}
            1 & \text{if } w_1 x_1 + w_2 x_2 + (-0.5) > 0 \\
            0 & \text{otherwise}
            \end{cases}
            \]
            \begin{itemize}
                \item If $x_1 = 1$ and $x_2 = 1$, $\text{Output} = 2 - 0.5 = 1.5$ (True)
                \item If $x_1 = 0$ and $x_2 = 1$, $\text{Output} = 1 - 0.5 = 0.5$ (True)
                \item If $x_1 = 1$ and $x_2 = 0$, $\text{Output} = 1 - 0.5 = 0.5$ (True)
                \item If $x_1 = 0$ and $x_2 = 0$, $\text{Output} = - 0.5 = -0.5$ (False)
            \end{itemize}
        \end{itemize}
        
        \item \textbf{AND Gate Implementation:}
        \begin{itemize}
            \item Inputs: \( x_1 \), \( x_2 \)
            \item Weights: \( w_1 = 1 \), \( w_2 = 1 \)
            \item Bias: \( -1.5 \)
            \item Output: 
            \[
            \text{Output} = 
            \begin{cases}
            1 & \text{if } w_1 x_1 + w_2 x_2 + (-1.5) > 0 \\
            0 & \text{otherwise}
            \end{cases}
            \]
            \begin{itemize}
                \item If $x_1 = 1$ and $x_2 = 1$, $\text{Output} = 2 - 1.5 = 0.5$ (True)
                \item If $x_1 = 0$ and $x_2 = 1$, $\text{Output} = 1 - 1.5 = -0.5$ (False)
                \item If $x_1 = 1$ and $x_2 = 0$, $\text{Output} = 1 - 1.5 = -0.5$ (False)
                \item If $x_1 = 0$ and $x_2 = 0$, $\text{Output} = - 1.5 = -1.5$ (False)
            \end{itemize}
        \end{itemize}
        
        \item \textbf{Function \( f = h_1\bar{h}_2 + \bar{h}_1 h_2 \) Implementation:}
        \begin{itemize}
            \item First term: \( h_1 \bar{h}_2 \) represents the AND of \( h_1 \) and \( \bar{h}_2 \)
            \item Second term: \( \bar{h}_1 h_2 \) represents the AND of the NOT of \( h_1 \) and \( h_2 \)
            \item Final output: 
            \[
            f = (h_1 \land \neg h_2) \lor (\neg h_1 \land h_2)
            \]
        \end{itemize}
    \end{itemize}    
\end{definition}

\subsection{Differentiable activation functions}
\begin{intuition}
    \begin{itemize}
        \item For linear/logistic regression, k-means clustering, MoG have differentiable objective functions that can be used to derive a learning algorithm. 
        \item $sgn(\underline{w}^T \underline{x})$ is not differentiable. 
    \end{itemize}
\end{intuition}

\begin{definition}
    Introduce continuous activation functions that are differentiable: 
    \begin{itemize}
        \item $\text{Logistic:} \quad g(z) = \frac{1}{1 + e^{-z}}$
        \item $\text{Tanh:} \quad g(z) = \frac{e^z - e^{-z}}{e^z + e^{-z}}$
    \end{itemize}
    \customFigure[0.5]{00_Images/AF.png}{Activation functions.}
\end{definition}

\subsection{Neural network}
\begin{example}
    \customFigure[0.5]{00_Images/NN.png}{Neural network with inputs, hidden units, and outputs that introduce the notation.}
    \begin{itemize}
        \item \textbf{Note:} The notation is given by $x_\#$ to be easier for the notation.
    \end{itemize}
\end{example}

\subsubsection{Application: Arbitrary 1D Function Approximation}
\begin{example}
    \begin{enumerate}
        \item \textbf{One hidden layer:}
        \item \textbf{Constructing a delta function}
        \begin{itemize}
            \item Constructing a delta function from the logistic function using $g(a+a/2)-g(ax-a/2)$.
            \item As $a\rightarrow \infty$, then you construct a delta function 
        \end{itemize}

        \item \textbf{Approximating any function}
        \begin{itemize}
            \item \textbf{Purpose:} There exists a set of parameters (i.e. hidden units) to arbitrary approximate the functions.
        \end{itemize}
    \end{enumerate}
    \customFigure[0.75]{00_Images/A1DF.png}{Approximating functions.}
\end{example}

\subsection{DL in Genomics (Real-life examples)}
\begin{example}
    \textbf{Detecting Protein Binding Sites in DNA}
    \customFigure[0.75]{00_Images/PB.png}{Protein binding}
    \begin{itemize}
        \item \textbf{B:} The disc is the set of representable functions, and it is initialized. The learning algorithm makes the function moves around until you reach the learned function. The true function will lie outside of the representable functions. 
    \end{itemize}
\end{example}

\begin{example}
    \customFigure[0.75]{00_Images/S2S.png}{1st layer weights}
\end{example}

\subsection{Mostly complete chart of NN}
\begin{definition}
    \customFigure[0.65]{00_Images/CNN.png}{Mostly complete chart of NN}
    \begin{itemize}
        \item \textbf{Key:} Lots of different architectures.
    \end{itemize}
\end{definition}

\subsection{Forward propogation}
\begin{definition}
    \begin{itemize}
        \item $I$ inputs, $O$ outputs, $H$ hidden units
        \item Total units $M = I + H + O$
        \item Index units so that connection $i \rightarrow j$ satisfies $i < j$
        \item Ordered activations:
        \[
        x_1, \ldots, x_I, x_{I+1}, \ldots, x_{I+H}, x_{M-O+1}, \ldots, x_M
        \]
        \begin{itemize}
            \item $x_1, \ldots, x_I$: Inputs
            \item $x_{I+1}, \ldots, x_{I+H}$: Hidden
            \item $x_{M-O+1}, \ldots, x_M$: Outputs
        \end{itemize}
        \item It is convenient to let $x_i$ be the pre-activation value for unit $i$
        \item Combining the above, we have
        \[
        \text{For } j > I, \quad x_j = \sum_{i=1}^{j-1} w_{ij} g_i(x_i)
        \]
        \begin{itemize}
            \item $g_i(x_i)$ is the activation function for $x_i$
            \item If $j$ is not connected to $i$, set $w_{ij} = 0$.
        \end{itemize}
    \end{itemize}
    \vspace{1em}
    
    \begin{itemize}
        \item If input unit $x_i$, $i \in \{1, \ldots, I\}$ is not transformed, set $g_i(x_i) = x_i$, i.e., $g_i$ is the identity.
        \begin{itemize}
            \item This means that for input units (the original features fed into the neural network), the activation function $g_i$ does not change the value of the input. 
        \end{itemize}
        \item The outputs of the neural network are $g_{M-O+1}(x_{M-O+1}), \ldots, g_M(x_M)$.
        \begin{itemize}
            \item The outputs are derived by applying the activation functions to the last set of units in the network.
            \item Here, $M$ represents the total number of units (including input, hidden, and output units)
            \item $O$ represents the number of output units. 
            \item $M-O+1$ to $M$ refers to the indices of the output units.
            \item The functions $g_{M-O+1}, \ldots, g_M$ represent the activation functions associated with each output unit. 
        \end{itemize}
    \end{itemize}    
\end{definition}

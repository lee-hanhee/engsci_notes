\documentclass{article}
\AtBeginDocument{\RenewCommandCopy\qty\SI}
\usepackage{style}
\title{ECE421 Cheatsheet}
\author{Hanhee Lee}
\lhead{ECE421}
\rhead{Hanhee Lee}

\begin{document}
\maketitle

\tableofcontents

\listoffigures

\listoftables

\section{Introduction to ML, Nearest neighbors, Linear classification (LFD: 1.1-1.2)}
\input{00_Lectures/W1.tex}

\section{Linear regression, Regularization (LFD: 3.2.1, 3.4.1, Appendix B)}
\input{00_Lectures/W2.tex}

\section{Logistic Regression (LFD: 3.3)}
\input{00_Lectures/W3.tex}

\section{Gradient Descent (LFD: 3.3, DL: 8.3.1-8.3.3 (recommended))}
\input{00_Lectures/W4.tex}

\section{Multilayer Perceptron, Neural Networks (LFD: Sec 7.1, 7.2.1, 7.2.2)}
\input{00_Lectures/W5.tex}

\section{Backpropagation, Neural Networks Implementations (LFD: 7.2, DL: 7.12, 8.4, 8.5 (recommended))}
\input{00_Lectures/W6.tex}

\section{Unsupervised Learning, Clustering, Density Estimation (LFD: 6.3.3, 6.4)}
\input{00_Lectures/W7.tex}

\section{EM (LFD: 6.4)}
\input{00_Lectures/W8.tex}

\section{Markov Decision Process (AIMA: 16)}
\input{00_Lectures/W9.tex}

\section{Reinforcement Learning (AIMA: 23.1-23.4)}
\input{00_Lectures/W10.tex}

\section{Deep Learning Architectures CNN; Language Models; RNN; Sequence modeling and neural machine translation; Attention; LSTM (PRML: Sec 5.5.6, DL: Sec 10.1, 10.2, 10.4, 10.10, SLP: Ch. 9)}
\input{00_Lectures/W11.tex}
\end{document}
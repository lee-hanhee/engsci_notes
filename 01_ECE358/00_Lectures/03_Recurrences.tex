\subsection{Recurrences introduction (Ch. 4.1)}
Divide-and-conquer method is useful to solve recurrences, which has three steps: 
\begin{enumerate}
    \item \textbf{Divide} the problem into one or more subproblems that are smaller instances of the same problem.
    \item \textbf{Conquer} the subproblems by solving them recursively.
    \item \textbf{Combine} the subproblem solutions to form a solution to the original problem.
\end{enumerate}

\begin{definition}
    A \textbf{recurrence} is an equation (or inequality) that describes a function in terms of its value on other, typically smaller, arguments.
    \begin{itemize}
        \item \textbf{Inequality:} You will use $\Omega$ (i.e. lower bound) or $O$ (i.e. upper bound).
    \end{itemize}
\end{definition}

\subsection{Mergesort (Motivation)}
    \begin{definition}
        The Merge Sort algorithm is defined as:
        \begin{equation}
            \text{mergesort}(A, p, r) \rightarrow \Theta (n \log n)
        \end{equation}
        where \( A \) is the array to be sorted, \( p \) is the starting index, and \( r \) is the ending index.   
       
        \begin{lstlisting}[language=Python, caption=Merge Sort Pseudocode]
            def merge_sort(A, p, r):
                if p >= r:                  # zero or one element?
                    return
                
                # If p < r
                q = (p + r) // 2            # midpoint of A[p : r] 
                merge_sort(A, p, q)         # recursively sort A[p : q] --> T(n/2)
                merge_sort(A, q + 1, r)     # recursively sort A[q + 1 : r] --> T(n/2)
                # Merge A[p : q] and A[q + 1 : r] into A[p : r]
                merge(A, p, q, r) # --> O(n)
        \end{lstlisting}   
        \vspace{1em}
        The time complexity of mergesort is
        \begin{equation}
            T(n) = 2T\left(\frac{n}{2}\right) + \Theta(n)
        \end{equation} 
        \begin{itemize}
            \item $2T(n/2)$ is the recursive time complexity of handling a subproblem half the size. 
            \item $O(n)$ is the linear time required to merge the results.
        \end{itemize}
    \end{definition}

    \customFigure[0.5]{00_Images/Merge_Sort.png}{Merge sort visualization, where we divide until there is one element, then merge by comparing them from least to greatest.}

\subsection{General examples}
These questions were salvulated as a quantity defined recursively in terms of a smaller value of itself.
\begin{example}
    We are tasked with solving the recurrence relation \( T(n) = T(n-1) + n \), with the base case \( T(1) = 1 \).

    \begin{enumerate}[label=\arabic*)]
        \item Start by expanding the recurrence:
        \[
        T(n) = T(n-1) + n
        \]
        Applying the recurrence again to \( T(n-1) \), we get:
        \[
        T(n) = [T(n-2) + (n-1)] + n = T(n-2) + (n-1) + n
        \]
        
        \item Continue expanding the recurrence iteratively:
        \[
        T(n) = [T(n-3) + (n-2)] + (n-1) + n = T(n-3) + (n-2) + (n-1) + n
        \]
        This process continues until we reach the base case \( T(1) = 1 \), which gives:
        \[
        T(n) = T(1) + 2 + 3 + \dots + n
        \]
        
        \item Now, express the expanded sum explicitly:
        \[
        T(n) = 1 + \sum_{i=2}^{n} i
        \]
        This sum can be simplified as:
        \[
        T(n) = \sum_{i=1}^{n} i
        \]
        
        \item Use the formula for the sum of the first \( n \) integers:
        \[
        \sum_{i=1}^{n} i = \frac{n(n+1)}{2}
        \]
        Thus, the closed form of the recurrence is:
        \[
        T(n) = \frac{n(n+1)}{2}
        \]
        
        \item Simplify this expression to:
        \[
        T(n) = \frac{1}{2}n^2 + \frac{1}{2}n
        \]
        Therefore, \( T(n) \) grows quadratically, and we conclude:
        \[
        T(n) = \Theta(n^2)
        \]
    \end{enumerate}
\end{example}

\begin{example}
    We are tasked with solving the recurrence \( T(n) = T\left(\frac{n}{2}\right) + n \), with the base case \( T(1) = 1 \).

    \begin{enumerate}[label=\arabic*)]
        \item Start by expanding the recurrence relation iteratively:
        \[
        T(n) = T\left(\frac{n}{2}\right) + n
        \]
        Applying the recurrence to \( T\left(\frac{n}{2}\right) \):
        \[
        T(n) = \left[T\left(\frac{n}{4}\right) + \frac{n}{2}\right] + n
        \]
        Continue expanding:
        \[
        T(n) = \left[T\left(\frac{n}{8}\right) + \frac{n}{4}\right] + \frac{n}{2} + n = \dots = T(1) + 1 + 2 + 4 + \dots + n
        \]

        \item The recurrence expands into a sum of powers of \( 2 \). In general, after \( \log_2 n \) expansions, the recurrence becomes:
        \[
        T(n) = T(1) + \sum_{i=0}^{\log_2 n - 1} \frac{n}{2^i}
        \]
        
        \item Simplify the sum:
        \[
        T(n) = 1 + n \sum_{i=0}^{\log_2 n - 1} \frac{1}{2^i}
        \]
        This is a geometric series with ratio \( \frac{1}{2} \), and the sum is given by:
        \[
        \sum_{i=0}^{\log_2 n - 1} \frac{1}{2^i} = \frac{1 - \left(\frac{1}{2}\right)^{\log_2 n}}{1 - \frac{1}{2}} = 2 \left(1 - \frac{1}{n}\right)
        \]
        
        \item Substituting this result back into the expression for \( T(n) \):
        \[
        T(n) = 1 + n \left(2 \left(1 - \frac{1}{n}\right)\right) = 1 + n(2 - 2/n) = 2n - 1
        \]
        
        \item Thus, the final expression is:
        \[
        T(n) = 2n - 1
        \]
        Therefore, the time complexity is:
        \[
        T(n) = \Theta(n)
        \]
    \end{enumerate}
\end{example}

\begin{example}
    We are tasked with solving the recurrence \( T(n) = 3T\left(\frac{n}{2}\right) + n \), with the base case \( T(1) = 1 \).

    \begin{enumerate}[label=\arabic*)]
        \item Start by expanding the recurrence iteratively:
        \[
        T(n) = 3T\left(\frac{n}{2}\right) + n
        \]
        Apply the recurrence again to \( T\left(\frac{n}{2}\right) \):
        \[
        T(n) = 3 \left[ 3T\left(\frac{n}{4}\right) + \frac{n}{2} \right] + n = 3^2 T\left(\frac{n}{4}\right) + 3 \cdot \frac{n}{2} + n
        \]
        Continue expanding iteratively:
        \[
        T(n) = 3^k T\left(\frac{n}{2^k}\right) + 3^{k-1} \cdot \frac{n}{2^{k-1}} + \dots + 3 \cdot \frac{n}{2} + n
        \]
        
        \item The expansion continues until \( \frac{n}{2^k} = 1 \), which implies \( k = \log_2 n \). At this point, \( T(1) = 1 \). Thus, the recurrence becomes:
        \[
        T(n) = 3^{\log_2 n} T(1) + \sum_{i=0}^{\log_2 n - 1} 3^i \cdot \frac{n}{2^i}
        \]
        Simplifying \( T(1) = 1 \), we get:
        \[
        T(n) = 3^{\log_2 n} + \sum_{i=0}^{\log_2 n - 1} 3^i \cdot \frac{n}{2^i}
        \]

        \item Next, simplify \( 3^{\log_2 n} \):
        \[
        3^{\log_2 n} = n^{\log_2 3}
        \]
        Now we evaluate the summation:
        \[
        \sum_{i=0}^{\log_2 n - 1} 3^i \cdot \frac{n}{2^i} = n \sum_{i=0}^{\log_2 n - 1} \left(\frac{3}{2}\right)^i
        \]
        This is a geometric series with ratio \( \frac{3}{2} \). The sum of the first \( \log_2 n \) terms is given by:
        \[
        \sum_{i=0}^{\log_2 n - 1} \left(\frac{3}{2}\right)^i = \frac{1 - \left(\frac{3}{2}\right)^{\log_2 n}}{1 - \frac{3}{2}} = 2 \left( 1 - \frac{1}{n^{\log_2 3}} \right)
        \]
        
        \item Substituting this into the recurrence gives:
        \[
        T(n) = n^{\log_2 3} + n \cdot 2 \left(1 - \frac{1}{n^{\log_2 3}}\right)
        \]
        Simplify the expression:
        \[
        T(n) = n^{\log_2 3} + 2n - 2
        \]

        \item Therefore, the final expression for \( T(n) \) is:
        \[
        T(n) = n^{\log_2 3} + 2n - 2
        \]
        Since \( n^{\log_2 3} \) dominates the expression as \( n \) grows large, we conclude that the time complexity is:
        \[
        T(n) = \Theta(n^{\log_2 3})
        \]
    \end{enumerate}
    \begin{itemize}
        \item The sum ends at $\log_2 n - 1$ because $\log_2 n$ indicates the number of levels, which can be found by drawing the recursion tree, but $-1$ removes the base case from the summation. 
    \end{itemize}
\end{example}

\subsection{Master theorem (Ch. 4.5 pg. 101-6)}
    \begin{theorem}
        Let \( a \geq 1 \), \( b > 1 \), and \( f(n) \) be a function, so that the recurrence is 

        \begin{equation}
            T(n) = aT\left(\frac{n}{b}\right) + f(n)
        \end{equation}

        Then the asymptotic behavior of \( T(n) \) is
        \begin{enumerate}
            \item If \( f(n) = O\left(n^{\log_b (a) - \epsilon}\right) \) for \( \epsilon > 0 \), then \( T(n) = \Theta\left(n^{\log_b a}\right) \).
            
            \item If \( f(n) = \Theta\left(n^{\log_b (a)}\right) \), then \( T(n) = \Theta\left(n^{\log_b a} \log n\right) \).
            
            \item If \( f(n) = \Omega\left(n^{\log_b (a) + \epsilon}\right) \) for \( \epsilon > 0 \) and \( af\left(\frac{n}{b}\right) \leq cf(n) \) for \( 0 < c < 1 \), then \( T(n) = \Theta(f(n)) \).
        \end{enumerate}
    \end{theorem}

    \begin{intuition}
        \begin{enumerate}
            \item \textbf{Case 1:} If $f(n)$ is upper bounded, then the subproblems dominate.
            \item \textbf{Case 2:} If $f(n)$ is tightly bounded, then the reccurrence grows slower.  
            \item \textbf{Case 3:} If $f(n)$ is lower bounded, then $f(n)$ dominates.
        \end{enumerate}
    \end{intuition}

    \begin{process}
        \begin{enumerate}
            \item Identify the recurrence relationship.
            \item State $a$, $b$, and $f(n)$. Make sure the conditions are met.
            \item Calculate $n^{\log_b a}$. 
            \item Compare $f(n)$ with $n^{\log_b a}$ to see which case the function applies too.
            \begin{enumerate}
                \item If $\epsilon$ case is used, then apply an abitrary value to see (usually natural numbers work well).
            \end{enumerate}
            \item Write down the answer by applying the Master Theorem.
        \end{enumerate}
    \end{process}
    
    \begin{example}
        Find the time complexity of Merge Sort using Master Theorem.
        \begin{enumerate}
            \item \textbf{Identify the Recurrence Relation:}
            \begin{itemize}
                \item The recurrence relation for the merge sort algorithm is given by:
                \[
                T(n) = 2T\left(\frac{n}{2}\right) + \Theta(n)
                \]
                \item This represents dividing the problem into two subproblems of half the size and then merging the results in linear time.
            \end{itemize}
        
            \item \textbf{State Parameters:}
            \begin{itemize}
                \item Compare the recurrence relation with the general form:
                \[
                T(n) = aT\left(\frac{n}{b}\right) + f(n)
                \]
                \item For the given problem:
                \begin{itemize}
                    \item \( a = 2 \): The number of subproblems.
                    \item \( b = 2 \): The factor by which the problem size is divided.
                    \item \( f(n) = \Theta(n) \): The cost of dividing and merging the results.
                \end{itemize}
            \end{itemize}
        
            \item \textbf{Calculate \( n^{\log_b a} \):}
            \begin{itemize}
                \item Compute \( \log_b a \):
                \[
                \log_b a = \log_2 2 = 1
                \]
                \item Thus, \( n^{\log_b a} = n^1 = n \).
            \end{itemize}
        
            \item \textbf{Compare \( f(n) \) with \( n^{\log_b a} \):}
            \begin{itemize}
                \item \( f(n) = \Theta(n) \) and \( n^{\log_b a} = n \).
                \item Since \( f(n) = \Theta(n) \) and \( f(n) = \Theta(n^{\log_b a}) = \Theta(n) \), this fits Case 2 of the Master Theorem.
            \end{itemize}
        
            \item \textbf{Apply the Master Theorem - Case 2:}
            \begin{itemize}
                \item Case 2 states: If \( f(n) = \Theta(n^{\log_b a}) \), then:
                \[
                T(n) = \Theta(n^{\log_b a} \log n) = \Theta(n \log n)
                \]
                \item Therefore, the time complexity of merge sort is:
                \[
                T(n) = \Theta(n \log n)
                \]
            \end{itemize}
        \end{enumerate}
    \end{example}

    \begin{example}
        Find the time complexity of this recurrence using Master Theorem.
        \begin{enumerate}
            \item \textbf{Identify the Recurrence Relation:}
            \begin{itemize}
                \item The recurrence relation is:
                \[
                T(n) = 9T\left(\frac{n}{3}\right) + n
                \]
            \end{itemize}
            
            \item \textbf{State Parameters:}
            \begin{itemize}
                \item Comparing with the general form \( T(n) = aT\left(\frac{n}{b}\right) + f(n) \), we have:
                \begin{itemize}
                    \item \( a = 9 \): Number of subproblems.
                    \item \( b = 3 \): Factor by which the problem size is divided.
                    \item \( f(n) = n \): The cost of the work done outside the recursive calls.
                \end{itemize}
            \end{itemize}
            
            \item \textbf{Calculate \( n^{\log_b a} \):}
            \begin{itemize}
                \item Compute \( \log_b a \):
                \[
                \log_3 9 = 2
                \]
                \item Thus, \( n^{\log_b a} = n^2 \).
            \end{itemize}
            
            \item \textbf{Compare \( f(n) \) with \( n^{\log_b a} \):}
            \begin{itemize}
                \item Given \( f(n) = n \), we have:
                \[
                f(n) = n = O\left(n^{\log_b a - \epsilon}\right) = O\left(n^{2-1}\right) = O(n)
                \]
                \item Since \( f(n) = O\left(n^{\log_b a - \epsilon}\right) \), this fits Case 1 of the Master Theorem.
            \end{itemize}
            
            \item \textbf{Apply the Master Theorem - Case 1:}
            \begin{itemize}
                \item Case 1 states: If \( f(n) = O\left(n^{\log_b a - \epsilon}\right) \) for some \( \epsilon > 0 \), then:
                \[
                T(n) = \Theta\left(n^{\log_b a}\right) = \Theta(n^2)
                \]
                \item Hence, the time complexity is:
                \[
                T(n) = \Theta(n^2)
                \]
            \end{itemize}
        \end{enumerate}
    \end{example}

    \begin{example}
        Find the time complexity of this recurrence using Master Theorem.
        \begin{enumerate}
            \item \textbf{Identify the Recurrence Relation:}
            \begin{itemize}
                \item The recurrence relation is:
                \[
                T(n) = 3T\left(\frac{n}{4}\right) + n \log(n)
                \]
            \end{itemize}
            
            \item \textbf{State Parameters:}
            \begin{itemize}
                \item Comparing with the general form \( T(n) = aT\left(\frac{n}{b}\right) + f(n) \), we have:
                \begin{itemize}
                    \item \( a = 3 \): Number of subproblems.
                    \item \( b = 4 \): Factor by which the problem size is divided.
                    \item \( f(n) = n \log(n) \): The cost of the work done outside the recursive calls.
                \end{itemize}
            \end{itemize}
            
            \item \textbf{Calculate \( n^{\log_b a} \):}
            \begin{itemize}
                \item Compute \( \log_b a \):
                \[
                \log_4 3 \approx 0.793
                \]
                \item Thus, \( n^{\log_b a} = n^{0.793} \).
            \end{itemize}
            
            \item \textbf{Compare \( f(n) \) with \( n^{\log_b a} \):}
            \begin{itemize}
                \item \( f(n) = n \log(n) \) is compared with \( \Omega\left(n^{0.793 + 0.2}\right) \), which implies:
                \[
                n \log(n) = \Omega\left(n^{0.993}\right)
                \]
                \item This indicates that \( f(n) \) dominates \( n^{\log_b a} \) with a polynomial difference, which suggests considering Case 3 of the Master Theorem.
            \end{itemize}
            
            \item \textbf{Verify Condition for Case 3 of the Master Theorem:}
            \begin{itemize}
                \item Check if \( af\left(\frac{n}{b}\right) \leq cf(n) \) for some \( c < 1 \):
                \[
                3 \left(\frac{n}{4}\right) \log\left(\frac{n}{4}\right) \leq \frac{3}{4} n \log(n)
                \]
                \item This inequality is true for the chosen constants, satisfying Case 3.
            \end{itemize}
            
            \item \textbf{Apply the Master Theorem - Case 3:}
            \begin{itemize}
                \item Since \( f(n) = \Omega\left(n^{\log_b a + \epsilon}\right) \) and the regularity condition is satisfied, we conclude:
                \[
                T(n) = \Theta(n \log n)
                \]
            \end{itemize}
        \end{enumerate}
    \end{example}

\subsection{Substitution (Ch. 4.3 pg. 90-4)}
    \begin{process}
        \begin{enumerate}
            \item Guess the form of the solution for $T(n)=?$ (This will be given on a test)
            \item Use induction to show that the solution works.
            \begin{enumerate}
                \item Basis: Find the base case using values of n that correspond (i.e. make sense) with the guessed solution.
                \item Inductive hypothesis:
                \item Inductive step:
            \end{enumerate}
            \item Find the constants.
        \end{enumerate}
    \end{process}
    
    \begin{intuition}
        \begin{itemize}
            \item \textbf{Avoid:} 
            \begin{itemize}
                \item Don't use asymptotic notation in the inductive hypothesis for the sub-method.
                \item You must be careful that the constants hidden by any asymptotic notation are the same constants throughout the proof.
            \end{itemize}
        \end{itemize}
    \end{intuition}

    \begin{example}
        Find the time complexity of the recurrence using sub-method. 
        \begin{enumerate}
            \item \textbf{Guess the Form of the Solution:}
            \begin{itemize}
                \item Given recurrence relation:
                \[
                T(n) = 2T\left(\left\lfloor \frac{n}{2} \right\rfloor\right) + n
                \]
                \item Guess: \( T(n) = cn \log n \).
            \end{itemize}
        
            \item \textbf{Basis:}
            \begin{itemize}
                \item For $n=1$, $T(1) \leq c \log 1 = 0$, therefore cannot use $n=1$ as the base case since a list of one element is already sorted (i.e. illogical).
                \item Check the base cases:
                \[
                T(2) = 4, \quad T(3) = 5
                \]
                \begin{itemize}
                    \item \textbf{Key:} Need double base case because recurrence splits in half. 
                    \item \textbf{Plugging into T:} $T(2) \leq c 2 \log 2 = 2c$ and $T(3) \leq c 3 \log 3 = c(3.0477)$, therefore, must pick $c \geq 3$.
                \end{itemize}
            \end{itemize}
            
            \item \textbf{Inductive Hypothesis:}
            \begin{itemize}
                \item Assume \( T(k) \leq O(k \log k) \) for all \( k < n \).
                \begin{itemize}
                    \item \textbf{Key:} Strictly less than $n$ to prove $T(n)$ as the step.
                \end{itemize}
                \item Specifically, assume:
                \[
                T\left( \left\lfloor \frac{n}{2} \right\rfloor \right) \leq c \left\lfloor \frac{n}{2} \right\rfloor \log\left( \left\lfloor \frac{n}{2} \right\rfloor \right) 
                \]
            \end{itemize}
        
            \item \textbf{Inductive Step:}
            \begin{itemize}
                \item Show it holds for \( T(n) \):
                \[
                T(n) = 2T\left(\left\lfloor \frac{n}{2} \right\rfloor\right) + n
                \]
                \item Substitute the inductive hypothesis:
                \[
                T(n) \leq 2 \left(c \cdot \left\lfloor \frac{n}{2} \right\rfloor \log\left(\left\lfloor \frac{n}{2} \right\rfloor \right)\right) + n
                \]

                \item Simplify:
                \[
                T(n)= cn \log\left(\frac{n}{2}\right) + n
                \]
                \item Use the logarithm property \( \log(ab) = \log a + \log b \):
                \[
                T(n)= cn(\log n - \log 2) + n
                \]
                \[
                T(n)= cn \log n - cn \log 2 + n
                \]
                \item $\log 2 = 1$ since base 2:
                \[
                T(n) = cn \log n + (1-c)n
                \]
                \item For sufficiently large $c$, then the 2nd term disappears because $(1-c)<0$
                \[
                T(n) \leq cn \log n
                \]       
            \end{itemize}
        \end{enumerate}
    \end{example}

    \begin{example}
        \[ T(n) = 2T\left( \frac{n}{2} \right) + n \quad \text{with} \quad T(1) = 1 \]

        \textbf{1. Proving \( T(n) = O(n \log n) \)}

        \begin{enumerate}[label=\arabic*)]
            \item \textbf{Guess:} \( T(n) = O(n \log n) \).
            \item \textbf{Hypothesis:} Assume \( T(k) \leq C \cdot k \log k \quad \forall k < n \), particularly for \( k = \frac{n}{2} \).
            \item \textbf{Inductive Step:} Now apply the recurrence to \( T(n) \):
            \[
            T(n) = 2T\left(\frac{n}{2}\right) + n
            \]
            Using the inductive hypothesis for \( T\left(\frac{n}{2}\right) \), we get:
            \[
            T(n) \leq 2 \left( C \cdot \frac{n}{2} \log \frac{n}{2} \right) + n
            \]
            Simplify the logarithmic term:
            \[
            T(n) = 2 \left( C \cdot \frac{n}{2} (\log n - 1) \right) + n
            \]
            \[
            T(n) = C \cdot n (\log n - 1) + n = C \cdot n \log n - C \cdot n + n
            \]
            \[
            T(n) = C \cdot n \log n + (1 - C) \cdot n
            \]
            \item For large \( n \), we can choose \( C \geq 1 \), so:
            \[
            T(n) \leq C \cdot n \log n \quad \forall n \geq 1
            \]
            Thus, \( T(n) = O(n \log n) \).
        \end{enumerate}

        \textbf{2. Proving \( T(n) = \Omega(n \log n) \)}

        \begin{enumerate}[label=\arabic*)]
            \item \textbf{Guess:} \( T(n) = \Omega(n \log n) \).
            \item \textbf{Hypothesis:} Assume \( T(k) \geq C \cdot k \log k \quad \forall k < n \), particularly for \( k = \frac{n}{2} \).
            \item \textbf{Inductive Step:} Now apply the recurrence to \( T(n) \):
            \[
            T(n) = 2T\left(\frac{n}{2}\right) + n
            \]
            Using the inductive hypothesis for \( T\left(\frac{n}{2}\right) \), we get:
            \[
            T(n) \geq 2 \left( C \cdot \frac{n}{2} \log \frac{n}{2} \right) + n
            \]
            Simplify the logarithmic term:
            \[
            T(n) = 2 \left( C \cdot \frac{n}{2} (\log n - 1) \right) + n
            \]
            \[
            T(n) = C \cdot n (\log n - 1) + n = C \cdot n \log n - C \cdot n + n
            \]
            \[
            T(n) = C \cdot n \log n + (1 - C) \cdot n
            \]
            \item For large \( n \), we can choose \( 0 < C \leq 1 \), so:
            \[
            T(n) \geq C \cdot n \log n \quad \forall n \geq 1
            \]
            Thus, \( T(n) = \Omega(n \log n) \).
        \end{enumerate}

        \textbf{Conclusion:}
        Since \( T(n) = O(n \log n) \) and \( T(n) = \Omega(n \log n) \), we conclude that:
        \[
        T(n) = \Theta(n \log n)
        \]
    \end{example}

    \begin{example}
        \[ T(n) = T\left( \frac{n}{2} \right) + T\left( \frac{n}{3} \right) + n \quad \text{with} \quad T(1) = 1 \]

        \textbf{1. Proving \( T(n) = O(n \log n) \)}

        \begin{enumerate}[label=\arabic*)]
            \item \textbf{Guess:} \( T(n) = O(n \log n) \).
            
            \item \textbf{Hypothesis:} Assume \( T(k) \leq C \cdot k \log k \quad \forall k < n \), particularly for \( k = \frac{n}{2} \) and \( k = \frac{n}{3} \).
            
            \item \textbf{Inductive Step:} Now apply the recurrence to \( T(n) \):
            \[
            T(n) = T\left( \frac{n}{2} \right) + T\left( \frac{n}{3} \right) + n
            \]
            Using the inductive hypothesis for \( T\left( \frac{n}{2} \right) \) and \( T\left( \frac{n}{3} \right) \), we get:
            \[
            T(n) \leq C \cdot \frac{n}{2} \log \frac{n}{2} + C \cdot \frac{n}{3} \log \frac{n}{3} + n
            \]
            
            Simplify the logarithmic terms:
            \[
            T(n) = C \cdot \frac{n}{2} (\log n - 1) + C \cdot \frac{n}{3} (\log n - \log 3) + n
            \]
            
            Combine terms:
            \[
            T(n) = C \cdot n \left( \frac{1}{2} \log n - \frac{1}{2} + \frac{1}{3} \log n - \frac{1}{3} \log 3 \right) + n
            \]
            \[
            T(n) = C \cdot n \left( \frac{5}{6} \log n - \left( \frac{1}{2} + \frac{1}{3} \log 3 \right) \right) + n
            \]
            
            Factor out \( C \cdot n \):
            \[
            T(n) = C \cdot n \left( \frac{5}{6} \log n \right) - C \cdot n \left( \frac{1}{2} + \frac{1}{3} \log 3 \right) + n
            \]
            
            \item Now simplify further:
            \[
            T(n) = \frac{5}{6} C \cdot n \log n - C \cdot n \left( \frac{1}{2} + \frac{1}{3} \log 3 \right) + n
            \]
            
            Finally, we have:
            \[
            T(n) \leq \frac{5}{6} C \cdot n \log n + n
            \]
            
            To ensure this holds, choose \( C \geq 1 \), so:
            \[
            T(n) \leq C \cdot n \log n \quad \forall n \geq 1
            \]
            
            Thus, \( T(n) = O(n \log n) \).

        \end{enumerate}
    \end{example}

    \begin{warning}
        Erroneous Induction
            Guess that \( T(n) = O(n) \)
            
            \textbf{Hypothesis:} Assume \( T\left( \frac{n}{2} \right) \leq 2C \frac{n}{2} \)
            
            \textbf{Step:}
            \[
            T(n) \leq 2C \left( \frac{n}{2} \right) + n
            \]
            \[
            \leq Cn + n
            \]
            \[
            = (C + 1)n = C'n
            \]
            
            \textbf{Problem:} \( C \) and \( C' \) are different constants, making this induction false by construction.
    \end{warning}

\subsection{Recursion tree method (Ch. 4.4 pg. 95-101)}
    \begin{definition}
        In a recursion tree, each node represents the cost of a single subproblem somewhere in the set of recursive function invocations.
    \end{definition}

    \begin{process}
        \begin{enumerate}
            \item Draw a recursion tree using $T(n)$ and split it off into the other $T$'s.
            \item Sum the work within each level of the tree to obtain the per-level work.
            \item Determine the height, which is $r^h n = 1$ 
            \begin{itemize}
                \item 1: When the recursion problem size is 1. 
                \item $r$: Largest value child from the root. 
                \item $n$: Initial problem size
                \item \textbf{Key:} The root's children bigger value determines the height of the tree as it will reach $O(1)$ (i.e. base-case) the slowest compared to the other branch, making it the longest path in the recursion tree. 
            \end{itemize}
            \item Determine the total work: $h \cdot \text{Work done at every level}$ 
        \end{enumerate}
    \end{process}

    \begin{intuition}
        How to make the recursion tree based on the recurrence.
    \end{intuition}

    \begin{example}
        \begin{enumerate}
            \item \textbf{Given Recurrence Relation:}
            \begin{itemize}
                \item The recurrence relation is:
                \[
                T(n) = T\left(\frac{n}{4}\right) + T\left(\frac{2n}{3}\right) + n
                \]
            \end{itemize}
            
            \item \textbf{Building the Recursion Tree:}
            \begin{itemize}
                \item The tree starts with \( T(n) \) at the root.
                \item Each node \( T(n) \) branches into two child nodes:
                \[
                T\left(\frac{n}{4}\right) \quad \text{and} \quad T\left(\frac{2n}{3}\right)
                \]
                \item This branching continues recursively until the problem size becomes $O(1)$ (base case).
            \end{itemize}
            \customFigure[0.75]{00_Images/Recursion_Tree.png}{Recursion tree that is made by subbing in the $T(\#)$ into the recurrence relation to get the nodes below.}
            
            \item \textbf{Calculating Work Done at Each Level:}
            \begin{itemize}
                \item At the root, the work done is \( n \).
                \item At the next level, the work is divided between:
                \[
                T\left(\frac{n}{4}\right) \quad \text{and} \quad T\left(\frac{2n}{3}\right)
                \]
                \item This pattern continues, and the work at each level is the sum of the work done by each subproblem.
                \item The total work at each level is \( n \), as shown by the distribution of the work across the nodes.
            \end{itemize}
            
            \item \textbf{Height of the Tree:}
            \begin{itemize}
                \item The longest path (height \( h \)) of the tree is determined by the rightmost path since \( \frac{2}{3} \) is larger than \( \frac{1}{4} \).
                \item The height \( h \) can be calculated using the formula:
                \[
                \left(\frac{2}{3}\right)^h \cdot n = 1
                \]
                \item Solving for \( h \):
                \[
                h = \log_{3/2}(n)
                \]
            \end{itemize}
            
            \item \textbf{Total Work Done in the Tree:}
            \begin{itemize}
                \item The total work is the sum of the work done at each level times the height of the tree:
                \[
                h \cdot n
                \]
                \item Substituting the value of \( h \):
                \[
                h \cdot n = \log_{3/2}(n) \cdot n
                \]
                \item This expression simplifies to:
                \[
                O(n \log n)
                \]
                \item Therefore, the total work done by the recursion tree is \( O(n \log n) \).
            \end{itemize}
        \end{enumerate}
    \end{example}

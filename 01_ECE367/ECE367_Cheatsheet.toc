\babel@toc {english}{}\relax 
\contentsline {section}{\numberline {1}QA}{6}{section.1}%
\contentsline {section}{\numberline {2}Vectors, Norms, Inner Products (Ch. 2.1-2.2)}{6}{section.2}%
\contentsline {subsection}{\numberline {2.1}Linear transformation}{6}{subsection.2.1}%
\contentsline {subsubsection}{\numberline {2.1.1}Matrix representation of a linear transformation}{6}{subsubsection.2.1.1}%
\contentsline {subsection}{\numberline {2.2}Vectors}{7}{subsection.2.2}%
\contentsline {subsection}{\numberline {2.3}Vector spaces}{7}{subsection.2.3}%
\contentsline {subsubsection}{\numberline {2.3.1}How to prove or disprove a vector space?}{7}{subsubsection.2.3.1}%
\contentsline {subsection}{\numberline {2.4}Subspace}{8}{subsection.2.4}%
\contentsline {subsection}{\numberline {2.5}Span}{9}{subsection.2.5}%
\contentsline {subsubsection}{\numberline {2.5.1}How to draw the span?}{9}{subsubsection.2.5.1}%
\contentsline {subsection}{\numberline {2.6}Linear independent (LI) set}{9}{subsection.2.6}%
\contentsline {subsubsection}{\numberline {2.6.1}How to determine if a set is linearly independent}{10}{subsubsection.2.6.1}%
\contentsline {subsection}{\numberline {2.7}Basis}{10}{subsection.2.7}%
\contentsline {subsubsection}{\numberline {2.7.1}Dimension}{10}{subsubsection.2.7.1}%
\contentsline {subsection}{\numberline {2.8}Norms (Notion of distance)}{11}{subsection.2.8}%
\contentsline {subsubsection}{\numberline {2.8.1}Norm balls}{11}{subsubsection.2.8.1}%
\contentsline {subsubsection}{\numberline {2.8.2}Motivation for Norms}{12}{subsubsection.2.8.2}%
\contentsline {subsubsection}{\numberline {2.8.3}Distance metric}{12}{subsubsection.2.8.3}%
\contentsline {subsection}{\numberline {2.9}Inner product (Notion of angle)}{12}{subsection.2.9}%
\contentsline {subsubsection}{\numberline {2.9.1}Examples of inner products}{13}{subsubsection.2.9.1}%
\contentsline {subsubsection}{\numberline {2.9.2}Connection of inner product to angle}{13}{subsubsection.2.9.2}%
\contentsline {subsubsection}{\numberline {2.9.3}Cauchy-Schwartz inequality and its generalization}{13}{subsubsection.2.9.3}%
\contentsline {subsubsection}{\numberline {2.9.4}Inner product induces a norm}{14}{subsubsection.2.9.4}%
\contentsline {subsection}{\numberline {2.10}Orthogonal decomposition}{14}{subsection.2.10}%
\contentsline {subsubsection}{\numberline {2.10.1}Mutually orthogonal}{14}{subsubsection.2.10.1}%
\contentsline {subsubsection}{\numberline {2.10.2}Orthonormal basis}{14}{subsubsection.2.10.2}%
\contentsline {subsubsection}{\numberline {2.10.3}Orthogonal}{15}{subsubsection.2.10.3}%
\contentsline {subsubsection}{\numberline {2.10.4}Orthogonal complement}{15}{subsubsection.2.10.4}%
\contentsline {section}{\numberline {3}Orthogonal Decomposition, Projecting onto Subspaces, Gram-Schmidt, QR Decomposition, Projection onto Affine Sets, Hyperplanes and Half-Spaces (Ch. 2.2-2.3)}{16}{section.3}%
\contentsline {subsection}{\numberline {3.1}Projection onto subspaces}{16}{subsection.3.1}%
\contentsline {subsubsection}{\numberline {3.1.1}Basic problem}{17}{subsubsection.3.1.1}%
\contentsline {subsubsection}{\numberline {3.1.2}Projection onto a 1D subspace}{17}{subsubsection.3.1.2}%
\contentsline {subsubsection}{\numberline {3.1.3}Projection onto an n dimensional space}{18}{subsubsection.3.1.3}%
\contentsline {subsubsection}{\numberline {3.1.4}Application of projections: Fourier series}{19}{subsubsection.3.1.4}%
\contentsline {subsection}{\numberline {3.2}Gram-Schmidt and QR decomposition}{20}{subsection.3.2}%
\contentsline {subsubsection}{\numberline {3.2.1}What if the set of basis vectors is not orthonormal?}{20}{subsubsection.3.2.1}%
\contentsline {subsubsection}{\numberline {3.2.2}Gram-Schmidt Procedure}{21}{subsubsection.3.2.2}%
\contentsline {subsubsection}{\numberline {3.2.3}QR decomposition}{22}{subsubsection.3.2.3}%
\contentsline {subsection}{\numberline {3.3}Projection of a subspace defined by its orthogonal vectors}{23}{subsection.3.3}%
\contentsline {subsubsection}{\numberline {3.3.1}Subspace defined by its orthogonal vectors}{23}{subsubsection.3.3.1}%
\contentsline {subsubsection}{\numberline {3.3.2}Projection}{24}{subsubsection.3.3.2}%
\contentsline {subsection}{\numberline {3.4}Projection onto affine sets}{25}{subsection.3.4}%
\contentsline {subsubsection}{\numberline {3.4.1}Affine spaces}{25}{subsubsection.3.4.1}%
\contentsline {subsubsection}{\numberline {3.4.2}Projection of Affine space defined in terms of basis vectors of corresponding subspace}{26}{subsubsection.3.4.2}%
\contentsline {subsubsection}{\numberline {3.4.3}Projection of Affine space defined in terms of orthogonal vectors to corresponding subspace}{28}{subsubsection.3.4.3}%
\contentsline {subsubsection}{\numberline {3.4.4}Show that the two affine sets are equal}{29}{subsubsection.3.4.4}%
\contentsline {subsection}{\numberline {3.5}Summary}{30}{subsection.3.5}%
\contentsline {subsection}{\numberline {3.6}Hyperplanes and half-spaces}{31}{subsection.3.6}%
\contentsline {section}{\numberline {4}Problem set 1}{33}{section.4}%
\contentsline {section}{\numberline {5}Non-Euclidean Projection, Functions, Gradients and Hessians (Ch. 2.3-2.4)}{34}{section.5}%
\contentsline {subsection}{\numberline {5.1}Non-Euclidean projection}{34}{subsection.5.1}%
\contentsline {subsection}{\numberline {5.2}Functions}{35}{subsection.5.2}%
\contentsline {subsubsection}{\numberline {5.2.1}Terminology of functions}{36}{subsubsection.5.2.1}%
\contentsline {subsubsection}{\numberline {5.2.2}Common Sets}{36}{subsubsection.5.2.2}%
\contentsline {subsubsection}{\numberline {5.2.3}Linear functions}{38}{subsubsection.5.2.3}%
\contentsline {subsection}{\numberline {5.3}Function approximations}{39}{subsection.5.3}%
\contentsline {subsubsection}{\numberline {5.3.1}Gradients}{39}{subsubsection.5.3.1}%
\contentsline {subsubsection}{\numberline {5.3.2}First-Order Approximation}{39}{subsubsection.5.3.2}%
\contentsline {subsubsection}{\numberline {5.3.3}Gradient properties}{40}{subsubsection.5.3.3}%
\contentsline {subsubsection}{\numberline {5.3.4}Tangent plane}{41}{subsubsection.5.3.4}%
\contentsline {subsubsection}{\numberline {5.3.5}Second order approximations}{43}{subsubsection.5.3.5}%
\contentsline {subsubsection}{\numberline {5.3.6}Hessians}{43}{subsubsection.5.3.6}%
\contentsline {subsubsection}{\numberline {5.3.7}Approximating}{43}{subsubsection.5.3.7}%
\contentsline {section}{\numberline {6}Matrices, Range, Null Space, Eigenvalues, Eigenvectors, Matrix Diagonalization (Ch. 3.1-3.5)}{44}{section.6}%
\contentsline {subsection}{\numberline {6.1}Matrices}{44}{subsection.6.1}%
\contentsline {subsubsection}{\numberline {6.1.1}Matrix Transpose}{44}{subsubsection.6.1.1}%
\contentsline {subsubsection}{\numberline {6.1.2}Matrix Multiplication}{44}{subsubsection.6.1.2}%
\contentsline {subsubsection}{\numberline {6.1.3}Matrix vector multiplication}{44}{subsubsection.6.1.3}%
\contentsline {subsubsection}{\numberline {6.1.4}Block Matrix Product}{44}{subsubsection.6.1.4}%
\contentsline {subsubsection}{\numberline {6.1.5}Types of Matrices}{45}{subsubsection.6.1.5}%
\contentsline {subsubsection}{\numberline {6.1.6}Matrices as Linear Maps}{45}{subsubsection.6.1.6}%
\contentsline {subsection}{\numberline {6.2}Range Space}{46}{subsection.6.2}%
\contentsline {subsection}{\numberline {6.3}Null Space}{47}{subsection.6.3}%
\contentsline {subsection}{\numberline {6.4}Fundamental theorem of algebra}{47}{subsection.6.4}%
\contentsline {subsubsection}{\numberline {6.4.1}Rank of A}{48}{subsubsection.6.4.1}%
\contentsline {subsection}{\numberline {6.5}Determinant}{49}{subsection.6.5}%
\contentsline {subsection}{\numberline {6.6}Matrix inner product and norm}{50}{subsection.6.6}%
\contentsline {subsubsection}{\numberline {6.6.1}Frobenius Norm}{50}{subsubsection.6.6.1}%
\contentsline {subsubsection}{\numberline {6.6.2}Operator norm (Motivation for eigenvalues and eigenvectors):}{51}{subsubsection.6.6.2}%
\contentsline {subsection}{\numberline {6.7}Eigenvalues and Eigenvectors}{52}{subsection.6.7}%
\contentsline {subsubsection}{\numberline {6.7.1}Characteristic polynomial}{52}{subsubsection.6.7.1}%
\contentsline {subsubsection}{\numberline {6.7.2}Geometric and algebraic multiplicity}{52}{subsubsection.6.7.2}%
\contentsline {subsubsection}{\numberline {6.7.3}Defective and non-defective}{52}{subsubsection.6.7.3}%
\contentsline {subsubsection}{\numberline {6.7.4}Eigenvectors corresponding to different eigenvalues are l.i.}{52}{subsubsection.6.7.4}%
\contentsline {subsection}{\numberline {6.8}Matrix Diagonalization}{54}{subsection.6.8}%
\contentsline {subsubsection}{\numberline {6.8.1}What does this diagonalization mean?}{55}{subsubsection.6.8.1}%
\contentsline {subsection}{\numberline {6.9}Application: Google's PageRank Algorithm}{56}{subsection.6.9}%
\contentsline {subsubsection}{\numberline {6.9.1}How to measure importance of a webpage}{56}{subsubsection.6.9.1}%
\contentsline {subsubsection}{\numberline {6.9.2}Example: Random Walk across Webpages}{56}{subsubsection.6.9.2}%
\contentsline {subsubsection}{\numberline {6.9.3}Convergence to a Steady State Distribution}{57}{subsubsection.6.9.3}%
\contentsline {subsubsection}{\numberline {6.9.4}Conditions for Convergence}{57}{subsubsection.6.9.4}%
\contentsline {subsubsection}{\numberline {6.9.5}Practical Modification}{57}{subsubsection.6.9.5}%
\contentsline {subsubsection}{\numberline {6.9.6}Why is 1 an eigenvalue of P?}{57}{subsubsection.6.9.6}%
\contentsline {subsubsection}{\numberline {6.9.7}What about other eigenvalues?}{58}{subsubsection.6.9.7}%
\contentsline {subsubsection}{\numberline {6.9.8}Convergence via Power Iteration}{58}{subsubsection.6.9.8}%
\contentsline {section}{\numberline {7}Problem set 2}{59}{section.7}%
\contentsline {subsection}{\numberline {7.1}Calculating inverse of a matrix}{59}{subsection.7.1}%
\contentsline {subsection}{\numberline {7.2}Finding rank and dimension/basis for range and null space of A and A transpose}{61}{subsection.7.2}%
\contentsline {section}{\numberline {8}Symmetric Matrices, Orthogonal Matrices, Spectral Decomposition, Positive Semidefinite Matrices, Ellipsoids (Ch. 4.1-4.4)}{62}{section.8}%
\contentsline {subsection}{\numberline {8.1}QA}{62}{subsection.8.1}%
\contentsline {subsection}{\numberline {8.2}Symmetric matrices}{62}{subsection.8.2}%
\contentsline {subsubsection}{\numberline {8.2.1}Example of symmetric matrix: Hessian Matrix}{62}{subsubsection.8.2.1}%
\contentsline {subsubsection}{\numberline {8.2.2}Theorem}{65}{subsubsection.8.2.2}%
\contentsline {subsection}{\numberline {8.3}Spectral decomposition}{66}{subsection.8.3}%
\contentsline {subsubsection}{\numberline {8.3.1}Spectral theorem}{66}{subsubsection.8.3.1}%
\contentsline {subsubsection}{\numberline {8.3.2}Difference between Eigendecomposition and Spectral Decomposition}{67}{subsubsection.8.3.2}%
\contentsline {subsection}{\numberline {8.4}Orthogonal matrices}{67}{subsection.8.4}%
\contentsline {subsubsection}{\numberline {8.4.1}What happens when we multiply a vector by an orthogonal matrix?}{67}{subsubsection.8.4.1}%
\contentsline {subsubsection}{\numberline {8.4.2}What kind of transformation corresponds to multiplying by a symmetric matrix?}{69}{subsubsection.8.4.2}%
\contentsline {subsection}{\numberline {8.5}Positive semidefinite matrices and positive definite matrices}{70}{subsection.8.5}%
\contentsline {subsubsection}{\numberline {8.5.1}Theorem on PSD,PD for Eigenvalues}{70}{subsubsection.8.5.1}%
\contentsline {subsection}{\numberline {8.6}Ellipsoids}{71}{subsection.8.6}%
\contentsline {subsection}{\numberline {8.7}Multivariate Gaussian Varibles}{73}{subsection.8.7}%
\contentsline {subsection}{\numberline {8.8}Sqaure roots of PSD}{74}{subsection.8.8}%
\contentsline {section}{\numberline {9}Singular Value Decomposition, Principal Component Analysis (Ch. 5.1, 5.3.2)}{76}{section.9}%
\contentsline {subsection}{\numberline {9.1}2nd Optimization Problem (Motivation for SVD)}{76}{subsection.9.1}%
\contentsline {subsection}{\numberline {9.2}3rd Optimization Problem}{77}{subsection.9.2}%
\contentsline {subsubsection}{\numberline {9.2.1}Theorem}{78}{subsubsection.9.2.1}%
\contentsline {subsection}{\numberline {9.3}Singular value decomposition}{79}{subsection.9.3}%
\contentsline {subsubsection}{\numberline {9.3.1}Intuition on SVD:}{80}{subsubsection.9.3.1}%
\contentsline {subsection}{\numberline {9.4}Proof of SVD}{80}{subsection.9.4}%
\contentsline {subsubsection}{\numberline {9.4.1}$AA^T$ and $A^T A$}{80}{subsubsection.9.4.1}%
\contentsline {subsubsection}{\numberline {9.4.2}Fact}{81}{subsubsection.9.4.2}%
\contentsline {subsubsection}{\numberline {9.4.3}How are u and v related?}{81}{subsubsection.9.4.3}%
\contentsline {subsubsection}{\numberline {9.4.4}Summarization of Steps for SVD Construction}{82}{subsubsection.9.4.4}%
\contentsline {subsubsection}{\numberline {9.4.5}Orthogonality of \( u^{(i)} \)'s}{82}{subsubsection.9.4.5}%
\contentsline {subsubsection}{\numberline {9.4.6}Why does this correspond to SVD?}{82}{subsubsection.9.4.6}%
\contentsline {subsubsection}{\numberline {9.4.7}Completing SVD:}{83}{subsubsection.9.4.7}%
\contentsline {subsubsection}{\numberline {9.4.8}Fact:}{83}{subsubsection.9.4.8}%
\contentsline {subsection}{\numberline {9.5}SVD in Two Forms}{83}{subsection.9.5}%
\contentsline {subsection}{\numberline {9.6}Maximization Problem}{84}{subsection.9.6}%
\contentsline {subsection}{\numberline {9.7}SVD Relation to Range space and Null space of A}{85}{subsection.9.7}%
\contentsline {subsection}{\numberline {9.8}What about A transpose?}{87}{subsection.9.8}%
\contentsline {subsubsection}{\numberline {9.8.1}Range and Null Space}{88}{subsubsection.9.8.1}%
\contentsline {subsection}{\numberline {9.9}Matrix Inverse}{88}{subsection.9.9}%
\contentsline {subsection}{\numberline {9.10}Pseudo-Inverse}{88}{subsection.9.10}%
\contentsline {subsubsection}{\numberline {9.10.1}Least Squares Solution}{89}{subsubsection.9.10.1}%
\contentsline {subsection}{\numberline {9.11}Matrix Norms}{89}{subsection.9.11}%
\contentsline {subsubsection}{\numberline {9.11.1}Frobenius Norm}{89}{subsubsection.9.11.1}%
\contentsline {subsubsection}{\numberline {9.11.2}Operator Norm}{90}{subsubsection.9.11.2}%
\contentsline {subsection}{\numberline {9.12}Conditioning Number of a Matrix}{90}{subsection.9.12}%
\contentsline {subsubsection}{\numberline {9.12.1}Stability}{90}{subsubsection.9.12.1}%
\contentsline {subsection}{\numberline {9.13}Latent Semantic Indexing}{91}{subsection.9.13}%
\contentsline {subsection}{\numberline {9.14}Principle component analysis}{92}{subsection.9.14}%
\contentsline {section}{\numberline {10}Interpretations of SVD, Low-Rank Approximation (Ch. 5.2-5.3.1)}{96}{section.10}%
\contentsline {subsection}{\numberline {10.1}Low-rank approximation}{96}{subsection.10.1}%
\contentsline {section}{\numberline {11}Least Squares, Overdetermined and Underdetermined Linear Equations (Ch. 6.1-6.4)}{97}{section.11}%
\contentsline {subsection}{\numberline {11.1}Least squares}{97}{subsection.11.1}%
\contentsline {subsubsection}{\numberline {11.1.1}Motivation:}{97}{subsubsection.11.1.1}%
\contentsline {subsection}{\numberline {11.2}Overdetermined linear equation}{97}{subsection.11.2}%
\contentsline {subsubsection}{\numberline {11.2.1}Why the solution has a pseudo inverse form?}{99}{subsubsection.11.2.1}%
\contentsline {subsubsection}{\numberline {11.2.2}Pseudo Inverse}{100}{subsubsection.11.2.2}%
\contentsline {subsubsection}{\numberline {11.2.3}Application: Linear Regression}{101}{subsubsection.11.2.3}%
\contentsline {subsubsection}{\numberline {11.2.4}Application: Polynomial Regression}{103}{subsubsection.11.2.4}%
\contentsline {subsubsection}{\numberline {11.2.5}Regularized LS:}{103}{subsubsection.11.2.5}%
\contentsline {subsection}{\numberline {11.3}Underdetermined linear equation}{104}{subsection.11.3}%
\contentsline {subsubsection}{\numberline {11.3.1}Application: Optimal Control}{107}{subsubsection.11.3.1}%
\contentsline {section}{\numberline {12}Regularized Least-Squares, Convex Sets and Convex Functions (Ch. 6.7.3, 8.1-8.4)}{109}{section.12}%
\contentsline {subsection}{\numberline {12.1}Regularized least-squares}{109}{subsection.12.1}%
\contentsline {subsubsection}{\numberline {12.1.1}Application: Sparse Coding of Images}{110}{subsubsection.12.1.1}%
\contentsline {subsection}{\numberline {12.2}Convex sets and convex functions}{111}{subsection.12.2}%
\contentsline {subsubsection}{\numberline {12.2.1}General Form of an Optimization Problem}{111}{subsubsection.12.2.1}%
\contentsline {subsubsection}{\numberline {12.2.2}Convex Set:}{112}{subsubsection.12.2.2}%
\contentsline {subsubsection}{\numberline {12.2.3}Process for proving convex:}{113}{subsubsection.12.2.3}%
\contentsline {subsubsection}{\numberline {12.2.4}Convex Function:}{115}{subsubsection.12.2.4}%
\contentsline {subsubsection}{\numberline {12.2.5}Concave Function}{115}{subsubsection.12.2.5}%
\contentsline {subsubsection}{\numberline {12.2.6}Connection Between Convex Sets and Convex Functions}{116}{subsubsection.12.2.6}%
\contentsline {subsubsection}{\numberline {12.2.7}Convex Optimization Problem (Motivation for Convex)}{117}{subsubsection.12.2.7}%
\contentsline {subsubsection}{\numberline {12.2.8}Differentiable Convex Functions}{118}{subsubsection.12.2.8}%
\contentsline {subsubsection}{\numberline {12.2.9}Solving Unconstrained Optimization Problems}{121}{subsubsection.12.2.9}%
\contentsline {section}{\numberline {13}Lagrangian Method for Constrained Optimization, Linear Programming and Quadratic Programming (Ch. 8.5, 9.1-9.6)}{126}{section.13}%
\contentsline {subsection}{\numberline {13.1}Lagrangian method for constrained optimization}{126}{subsection.13.1}%
\contentsline {subsubsection}{\numberline {13.1.1}Constrained Optimization Problem}{126}{subsubsection.13.1.1}%
\contentsline {subsubsection}{\numberline {13.1.2}Convex Optimization Problem}{127}{subsubsection.13.1.2}%
\contentsline {subsubsection}{\numberline {13.1.3}Theorem}{127}{subsubsection.13.1.3}%
\contentsline {subsection}{\numberline {13.2}Lagrangian Method}{128}{subsection.13.2}%
\contentsline {subsubsection}{\numberline {13.2.1}Theorem}{129}{subsubsection.13.2.1}%
\contentsline {subsubsection}{\numberline {13.2.2}Example}{129}{subsubsection.13.2.2}%
\contentsline {subsection}{\numberline {13.3}Linear programming and quadratic programming}{131}{subsection.13.3}%
\contentsline {subsubsection}{\numberline {13.3.1}Linear Programming}{131}{subsubsection.13.3.1}%
\contentsline {subsubsection}{\numberline {13.3.2}\( \ell _1 \) and \( \ell _\infty \) Minimization Problems}{133}{subsubsection.13.3.2}%
\contentsline {section}{\numberline {14}Numerical Algorithms for Unconstrained and Constrained Optimization (Ch. 12.1-12.3)}{136}{section.14}%
\contentsline {subsection}{\numberline {14.1}Numerical algorithms for unconstrained optimization}{136}{subsection.14.1}%
\contentsline {subsection}{\numberline {14.2}Numerical algorithms for constrained optimization}{136}{subsection.14.2}%

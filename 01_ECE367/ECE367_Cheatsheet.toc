\babel@toc {english}{}\relax 
\contentsline {section}{\numberline {1}QA}{4}{section.1}%
\contentsline {section}{\numberline {2}Vectors, Norms, Inner Products (Ch. 2.1-2.2)}{4}{section.2}%
\contentsline {subsection}{\numberline {2.1}Linear transformation}{4}{subsection.2.1}%
\contentsline {subsubsection}{\numberline {2.1.1}Matrix representation of a linear transformation}{4}{subsubsection.2.1.1}%
\contentsline {subsection}{\numberline {2.2}Vectors}{5}{subsection.2.2}%
\contentsline {subsection}{\numberline {2.3}Vector spaces}{5}{subsection.2.3}%
\contentsline {subsubsection}{\numberline {2.3.1}How to prove or disprove a vector space?}{6}{subsubsection.2.3.1}%
\contentsline {subsection}{\numberline {2.4}Subspace}{7}{subsection.2.4}%
\contentsline {subsection}{\numberline {2.5}Span}{7}{subsection.2.5}%
\contentsline {subsubsection}{\numberline {2.5.1}How to draw the span?}{7}{subsubsection.2.5.1}%
\contentsline {subsection}{\numberline {2.6}Linear independent (LI) set}{8}{subsection.2.6}%
\contentsline {subsubsection}{\numberline {2.6.1}How to determine if a set is linearly independent}{8}{subsubsection.2.6.1}%
\contentsline {subsection}{\numberline {2.7}Basis}{8}{subsection.2.7}%
\contentsline {subsubsection}{\numberline {2.7.1}Dimension}{8}{subsubsection.2.7.1}%
\contentsline {subsection}{\numberline {2.8}Norms (Notion of distance)}{9}{subsection.2.8}%
\contentsline {subsubsection}{\numberline {2.8.1}Norm balls}{9}{subsubsection.2.8.1}%
\contentsline {subsubsection}{\numberline {2.8.2}Motivation for Norms}{10}{subsubsection.2.8.2}%
\contentsline {subsubsection}{\numberline {2.8.3}Distance metric}{10}{subsubsection.2.8.3}%
\contentsline {subsection}{\numberline {2.9}Inner product (Notion of angle)}{10}{subsection.2.9}%
\contentsline {subsubsection}{\numberline {2.9.1}Examples of inner products}{11}{subsubsection.2.9.1}%
\contentsline {subsubsection}{\numberline {2.9.2}Connection of inner product to angle}{11}{subsubsection.2.9.2}%
\contentsline {subsubsection}{\numberline {2.9.3}Cauchy-Schwartz inequality and its generalization}{11}{subsubsection.2.9.3}%
\contentsline {subsubsection}{\numberline {2.9.4}Inner product induces a norm}{12}{subsubsection.2.9.4}%
\contentsline {subsection}{\numberline {2.10}Orthogonal decomposition}{12}{subsection.2.10}%
\contentsline {subsubsection}{\numberline {2.10.1}Mutually orthogonal}{12}{subsubsection.2.10.1}%
\contentsline {subsubsection}{\numberline {2.10.2}Orthonormal basis}{12}{subsubsection.2.10.2}%
\contentsline {subsubsection}{\numberline {2.10.3}Orthogonal}{13}{subsubsection.2.10.3}%
\contentsline {subsubsection}{\numberline {2.10.4}Orthogonal complement}{13}{subsubsection.2.10.4}%
\contentsline {section}{\numberline {3}Orthogonal Decomposition, Projecting onto Subspaces, Gram-Schmidt, QR Decomposition, Projection onto Affine Sets, Hyperplanes and Half-Spaces (Ch. 2.2-2.3)}{14}{section.3}%
\contentsline {subsection}{\numberline {3.1}Projection onto subspaces}{14}{subsection.3.1}%
\contentsline {subsubsection}{\numberline {3.1.1}Basic problem}{15}{subsubsection.3.1.1}%
\contentsline {subsubsection}{\numberline {3.1.2}Projection onto a 1D subspace}{15}{subsubsection.3.1.2}%
\contentsline {subsubsection}{\numberline {3.1.3}Projection onto an n dimensional space}{16}{subsubsection.3.1.3}%
\contentsline {subsubsection}{\numberline {3.1.4}Application of projections: Fourier series}{17}{subsubsection.3.1.4}%
\contentsline {subsection}{\numberline {3.2}Gram-Schmidt and QR decomposition}{18}{subsection.3.2}%
\contentsline {subsubsection}{\numberline {3.2.1}What if the set of basis vectors is not orthonormal?}{18}{subsubsection.3.2.1}%
\contentsline {subsubsection}{\numberline {3.2.2}Gram-Schmidt Procedure}{19}{subsubsection.3.2.2}%
\contentsline {subsubsection}{\numberline {3.2.3}QR decomposition}{20}{subsubsection.3.2.3}%
\contentsline {subsection}{\numberline {3.3}Projection of a subspace defined by its orthogonal vectors}{21}{subsection.3.3}%
\contentsline {subsubsection}{\numberline {3.3.1}Subspace defined by its orthogonal vectors}{21}{subsubsection.3.3.1}%
\contentsline {subsubsection}{\numberline {3.3.2}Projection}{22}{subsubsection.3.3.2}%
\contentsline {subsection}{\numberline {3.4}Projection onto affine sets}{23}{subsection.3.4}%
\contentsline {subsubsection}{\numberline {3.4.1}Affine spaces}{23}{subsubsection.3.4.1}%
\contentsline {subsubsection}{\numberline {3.4.2}Projection of Affine space defined in terms of basis vectors of corresponding subspace}{24}{subsubsection.3.4.2}%
\contentsline {subsubsection}{\numberline {3.4.3}Projection of Affine space defined in terms of orthogonal vectors to corresponding subspace}{26}{subsubsection.3.4.3}%
\contentsline {subsubsection}{\numberline {3.4.4}Show that the two affine sets are equal}{27}{subsubsection.3.4.4}%
\contentsline {subsection}{\numberline {3.5}Summary}{28}{subsection.3.5}%
\contentsline {subsection}{\numberline {3.6}Hyperplanes and half-spaces}{29}{subsection.3.6}%
\contentsline {section}{\numberline {4}Problem set 1}{31}{section.4}%
\contentsline {section}{\numberline {5}Non-Euclidean Projection, Functions, Gradients and Hessians (Ch. 2.3-2.4)}{32}{section.5}%
\contentsline {subsection}{\numberline {5.1}Non-Euclidean projection}{32}{subsection.5.1}%
\contentsline {subsection}{\numberline {5.2}Functions}{33}{subsection.5.2}%
\contentsline {subsubsection}{\numberline {5.2.1}Terminology of functions}{34}{subsubsection.5.2.1}%
\contentsline {subsubsection}{\numberline {5.2.2}Common Sets}{34}{subsubsection.5.2.2}%
\contentsline {subsubsection}{\numberline {5.2.3}Linear functions}{36}{subsubsection.5.2.3}%
\contentsline {subsection}{\numberline {5.3}Function approximations}{37}{subsection.5.3}%
\contentsline {subsubsection}{\numberline {5.3.1}Gradients}{37}{subsubsection.5.3.1}%
\contentsline {subsubsection}{\numberline {5.3.2}First-Order Approximation}{37}{subsubsection.5.3.2}%
\contentsline {subsubsection}{\numberline {5.3.3}Gradient properties}{38}{subsubsection.5.3.3}%
\contentsline {subsubsection}{\numberline {5.3.4}Tangent plane}{39}{subsubsection.5.3.4}%
\contentsline {subsubsection}{\numberline {5.3.5}Second order approximations}{41}{subsubsection.5.3.5}%
\contentsline {subsubsection}{\numberline {5.3.6}Hessians}{41}{subsubsection.5.3.6}%
\contentsline {subsubsection}{\numberline {5.3.7}Approximating}{41}{subsubsection.5.3.7}%
\contentsline {section}{\numberline {6}Matrices, Range, Null Space, Eigenvalues, Eigenvectors, Matrix Diagonalization (Ch. 3.1-3.5)}{42}{section.6}%
\contentsline {subsection}{\numberline {6.1}Matrices}{42}{subsection.6.1}%
\contentsline {subsubsection}{\numberline {6.1.1}Matrix Transpose}{42}{subsubsection.6.1.1}%
\contentsline {subsubsection}{\numberline {6.1.2}Matrix Multiplication}{42}{subsubsection.6.1.2}%
\contentsline {subsubsection}{\numberline {6.1.3}Matrix vector multiplication}{42}{subsubsection.6.1.3}%
\contentsline {subsubsection}{\numberline {6.1.4}Block Matrix Product}{42}{subsubsection.6.1.4}%
\contentsline {subsubsection}{\numberline {6.1.5}Types of Matrices}{43}{subsubsection.6.1.5}%
\contentsline {subsubsection}{\numberline {6.1.6}Matrices as Linear Maps}{43}{subsubsection.6.1.6}%
\contentsline {subsection}{\numberline {6.2}Range Space}{44}{subsection.6.2}%
\contentsline {subsection}{\numberline {6.3}Null Space}{45}{subsection.6.3}%
\contentsline {subsection}{\numberline {6.4}Fundamental theorem of algebra}{45}{subsection.6.4}%
\contentsline {subsubsection}{\numberline {6.4.1}Rank of A}{46}{subsubsection.6.4.1}%
\contentsline {subsection}{\numberline {6.5}Determinant}{47}{subsection.6.5}%
\contentsline {subsection}{\numberline {6.6}Matrix inner product and norm}{48}{subsection.6.6}%
\contentsline {subsubsection}{\numberline {6.6.1}Frobenius Norm}{48}{subsubsection.6.6.1}%
\contentsline {subsubsection}{\numberline {6.6.2}Operator norm (Motivation for eigenvalues and eigenvectors):}{49}{subsubsection.6.6.2}%
\contentsline {subsection}{\numberline {6.7}Eigenvalues and Eigenvectors}{50}{subsection.6.7}%
\contentsline {subsubsection}{\numberline {6.7.1}Characteristic polynomial}{50}{subsubsection.6.7.1}%
\contentsline {subsubsection}{\numberline {6.7.2}Geometric and algebraic multiplicity}{50}{subsubsection.6.7.2}%
\contentsline {subsubsection}{\numberline {6.7.3}Defective and non-defective}{50}{subsubsection.6.7.3}%
\contentsline {subsubsection}{\numberline {6.7.4}Eigenvectors corresponding to different eigenvalues are l.i.}{50}{subsubsection.6.7.4}%
\contentsline {subsection}{\numberline {6.8}Matrix Diagonalization}{52}{subsection.6.8}%
\contentsline {subsubsection}{\numberline {6.8.1}What does this diagonalization mean?}{53}{subsubsection.6.8.1}%
\contentsline {subsection}{\numberline {6.9}Application: Google's PageRank Algorithm}{54}{subsection.6.9}%
\contentsline {subsubsection}{\numberline {6.9.1}How to measure importance of a webpage}{54}{subsubsection.6.9.1}%
\contentsline {subsubsection}{\numberline {6.9.2}Example: Random Walk across Webpages}{54}{subsubsection.6.9.2}%
\contentsline {subsubsection}{\numberline {6.9.3}Convergence to a Steady State Distribution}{55}{subsubsection.6.9.3}%
\contentsline {subsubsection}{\numberline {6.9.4}Conditions for Convergence}{55}{subsubsection.6.9.4}%
\contentsline {subsubsection}{\numberline {6.9.5}Practical Modification}{55}{subsubsection.6.9.5}%
\contentsline {subsubsection}{\numberline {6.9.6}Why is 1 an eigenvalue of P?}{55}{subsubsection.6.9.6}%
\contentsline {subsubsection}{\numberline {6.9.7}What about other eigenvalues?}{56}{subsubsection.6.9.7}%
\contentsline {subsubsection}{\numberline {6.9.8}Convergence via Power Iteration}{56}{subsubsection.6.9.8}%
\contentsline {section}{\numberline {7}Problem set 2}{57}{section.7}%
\contentsline {subsection}{\numberline {7.1}Calculating inverse of a matrix}{57}{subsection.7.1}%
\contentsline {subsection}{\numberline {7.2}Finding rank and dimension/basis for range and null space of A and A transpose}{59}{subsection.7.2}%
\contentsline {section}{\numberline {8}Symmetric Matrices, Orthogonal Matrices, Spectral Decomposition, Positive Semidefinite Matrices, Ellipsoids (Ch. 4.1-4.4)}{60}{section.8}%
\contentsline {subsection}{\numberline {8.1}Symmetric matrices}{60}{subsection.8.1}%
\contentsline {subsubsection}{\numberline {8.1.1}Example of symmetric matrix: Hessian Matrix}{60}{subsubsection.8.1.1}%
\contentsline {subsubsection}{\numberline {8.1.2}Theorem}{61}{subsubsection.8.1.2}%
\contentsline {subsection}{\numberline {8.2}Spectral decomposition}{62}{subsection.8.2}%
\contentsline {subsubsection}{\numberline {8.2.1}Spectral theorem}{62}{subsubsection.8.2.1}%
\contentsline {subsubsection}{\numberline {8.2.2}Difference between Eigendecomposition and Spectral Decomposition}{64}{subsubsection.8.2.2}%
\contentsline {subsection}{\numberline {8.3}Orthogonal matrices}{64}{subsection.8.3}%
\contentsline {subsubsection}{\numberline {8.3.1}What happens when we multiply a vector by an orthogonal matrix?}{64}{subsubsection.8.3.1}%
\contentsline {subsubsection}{\numberline {8.3.2}What kind of transformation corresponds to multiplying by a symmetric matrix?}{66}{subsubsection.8.3.2}%
\contentsline {subsection}{\numberline {8.4}Positive semidefinite matrices}{67}{subsection.8.4}%
\contentsline {subsection}{\numberline {8.5}Ellipsoids}{67}{subsection.8.5}%
\contentsline {section}{\numberline {9}Singular Value Decomposition, Principal Component Analysis (Ch. 5.1, 5.3.2)}{68}{section.9}%
\contentsline {subsection}{\numberline {9.1}Singular value decomposition}{68}{subsection.9.1}%
\contentsline {subsection}{\numberline {9.2}Principle component analysis}{68}{subsection.9.2}%
\contentsline {section}{\numberline {10}Interpretations of SVD, Low-Rank Approximation (Ch. 5.2-5.3.1)}{69}{section.10}%
\contentsline {subsection}{\numberline {10.1}Interpretation of SVD}{69}{subsection.10.1}%
\contentsline {subsection}{\numberline {10.2}Low-rank approximation}{69}{subsection.10.2}%
\contentsline {section}{\numberline {11}Least Squares, Overdetermined and Underdetermined Linear Equations (Ch. 6.1-6.4)}{70}{section.11}%
\contentsline {subsection}{\numberline {11.1}Least squares}{70}{subsection.11.1}%
\contentsline {subsection}{\numberline {11.2}Overdetermined linear equation}{70}{subsection.11.2}%
\contentsline {subsection}{\numberline {11.3}Underdetermined linear equation}{70}{subsection.11.3}%
\contentsline {section}{\numberline {12}Regularized Least-Squares, Convex Sets and Convex Functions (Ch. 6.7.3, 8.1-8.4)}{71}{section.12}%
\contentsline {subsection}{\numberline {12.1}Regularized least-squares}{71}{subsection.12.1}%
\contentsline {subsection}{\numberline {12.2}Convex sets and convex functions}{71}{subsection.12.2}%
\contentsline {section}{\numberline {13}Lagrangian Method for Constrained Optimization, Linear Programming and Quadratic Programming (Ch. 8.5, 9.1-9.6)}{72}{section.13}%
\contentsline {subsection}{\numberline {13.1}Lagrangian method for constrained optimization}{72}{subsection.13.1}%
\contentsline {subsection}{\numberline {13.2}Linear programming and quadratic programming}{72}{subsection.13.2}%
\contentsline {section}{\numberline {14}Numerical Algorithms for Unconstrained and Constrained Optimization (Ch. 12.1-12.3)}{73}{section.14}%
\contentsline {subsection}{\numberline {14.1}Numerical algorithms for unconstrained optimization}{73}{subsection.14.1}%
\contentsline {subsection}{\numberline {14.2}Numerical algorithms for constrained optimization}{73}{subsection.14.2}%
